# This file configures the `docs_integration` pipeline (https://dev.azure.com/great-expectations/great_expectations/_build)
#
# This pipeline runs tests against scripts that contain code samples that we use in our documentation.
#
# The pipeline is run under the following conditions:
#   - On any PR

trigger:
  branches:
    include:
    - develop

resources:
  containers:
  - container: postgres
    image: postgres:11
    ports:
    - 5432:5432
    env:
      POSTGRES_DB: "test_ci"
      POSTGRES_HOST_AUTH_METHOD: "trust"
  - container: mysql
    image: mysql:8.0.20
    ports:
      - 3306:3306
    env:
      MYSQL_ALLOW_EMPTY_PASSWORD: "yes"
      MYSQL_DATABASE: test_ci
  - container: mssql
    image: mcr.microsoft.com/mssql/server:2019-latest
    env:
      ACCEPT_EULA: Y
      MSSQL_SA_PASSWORD: ReallyStrongPwd1234%^&*
      MSSQL_DB: test_ci
      MSSQL_PID: Developer
    ports:
      - 1433:1433
  - container: trino
    image: trinodb/trino:400
    ports:
      - 8088:8080

variables:
  isDevelop: $[eq(variables['Build.SourceBranch'], 'refs/heads/develop')]
  isManual: $[eq(variables['Build.Reason'], 'Manual')]
  GE_USAGE_STATISTICS_URL: "https://qa.stats.greatexpectations.io/great_expectations/v1/usage_statistics"

stages:
  - stage: scope_check
    pool:
      vmImage: 'ubuntu-20.04'
    jobs:
      - job: changes
        steps:
          - task: ChangedFiles@1
            name: CheckDocsChanges
            inputs:
              verbose: true
              rules: |
                [DocsChanged]
                docs/**
                tests/integration/docusaurus/**
                tests/integration/fixtures/**
                tests/integration/test_definitions/**
                tests/integration/test_script_runner.py
                tests/test_sets/**

  - stage: docusaurus_tests
    dependsOn: scope_check
    pool:
      vmImage: 'ubuntu-latest'
    jobs:
    - job: test_docs_non_backend_specific
      timeoutInMinutes: 30
      condition: or(eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true), eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true), eq(variables.isDevelop, true), eq(variables.isManual, true))
      variables:
        python.version: '3.8'

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'

        - script: |
            pip install --constraint constraints-dev.txt ".[test]" pytest-azurepipelines
          displayName: 'Install dependencies'

        - script: |
            pytest -v --docs-tests -m integration tests/integration/test_script_runner.py
          displayName: 'pytest'

    - job: test_docs_spark
      timeoutInMinutes: 30
      condition: or(
          eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true),
          eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true),
          eq(variables.isDevelop, true),
          eq(variables.isManual, true)
        )
      variables:
        python.version: '3.8'

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'

        - script: |
            pip install --constraint constraints-dev.txt ".[test, spark]" pytest-azurepipelines
          displayName: 'Install dependencies'

        - script: |
            pytest -v --docs-tests -m integration --spark tests/integration/test_script_runner.py
          displayName: 'pytest'

    - job: test_docs_mysql
      timeoutInMinutes: 30
      condition: or(
          eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true),
          eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true),
          eq(variables.isDevelop, true),
          eq(variables.isManual, true)
        )
      variables:
        python.version: '3.8'
      services:
        mysql: mysql

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'

        - script: |
            pip install --constraint constraints-dev.txt ".[test, mysql]" pytest-azurepipelines
          displayName: 'Install dependencies'

        - script: |
            printf 'Waiting for MySQL database to accept connections'
            until mysql --host=localhost --protocol=TCP --port=3306 --user=root --password='' --execute "SHOW DATABASES"; do
              printf '.'
              sleep 1;
            done;
          displayName: Wait for database to initialise

        - script: |
            echo "SET GLOBAL sql_mode=(SELECT REPLACE(@@sql_mode,'ONLY_FULL_GROUP_BY',''));" > mysql_setup_script.sql
            mysql --host=localhost --protocol=TCP --port=3306 --user=root --password='' --reconnect < mysql_setup_script.sql
          displayName: 'Configure mysql'

        - script: |
            pytest -v --docs-tests -m integration --mysql tests/integration/test_script_runner.py
          displayName: 'pytest'

    - job: test_docs_postgresql
      timeoutInMinutes: 30
      condition: or(
          eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true),
          eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true),
          eq(variables.isDevelop, true),
          eq(variables.isManual, true)
        )
      variables:
        python.version: '3.8'
      services:
        postgres: postgres

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'

        - script: |
            pip install --constraint constraints-dev.txt ".[test, postgresql]" pytest-azurepipelines
          displayName: 'Install dependencies'

        - script: |
            pytest -v --docs-tests -m integration --postgresql tests/integration/test_script_runner.py
          displayName: 'pytest'

    - job: test_docs_bigquery
      timeoutInMinutes: 30
      condition: and(or(eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true), eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true), eq(variables.isDevelop, true), eq(variables.isManual, true)), ne(variables['SYSTEM.PULLREQUEST.ISFORK'], true))
      variables:
        python.version: '3.8'

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'

        - script: |
            # "Deprecated API features detected" warning/error for test_docs[split_data_on_whole_table_bigquery] when pandas>=2.0
            pip install --constraint constraints-dev.txt ".[test, bigquery]" pytest-azurepipelines "pandas<2.0.0"
          displayName: 'Install dependencies'
        - task: DownloadSecureFile@1
          name: gcp_authkey
          displayName: 'Download GCS Credentials'
          inputs:
              secureFile: 'superconductive-service-acct_ge-oss-ci-cd.json'
              retryCount: '2'

        - script: |
            # this is recommended by the Google documentation for CI/CD https://cloud.google.com/sdk/docs/install#other_installation_options
            curl -sS https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-370.0.0-linux-x86_64.tar.gz > ./google-cloud-sdk-370.0.0-linux-x86_64.tar.gz && tar -xf ./google-cloud-sdk-370.0.0-linux-x86_64.tar.gz
            ./google-cloud-sdk/install.sh --usage-reporting=False --path-update=True --quiet --install-python=False
            # creating new named configuration
            ./google-cloud-sdk/bin/gcloud config configurations create ge-oss-ci-cd-configurations
            # setting account config using project and service account info
            ./google-cloud-sdk/bin/gcloud config set account account-for-azure-tests --project=$(GE_TEST_GCP_PROJECT) --access-token-file=$(gcp_authkey.secureFilePath)
            # Pass the configured Cloud SDK authentication to gsutil.
            ./google-cloud-sdk/bin/gcloud config set pass_credentials_to_gsutil True
            # Authorize access to Google Cloud with a service account
            ./google-cloud-sdk/bin/gcloud auth activate-service-account --key-file=$(gcp_authkey.secureFilePath)
          displayName: 'Install and setup Google Cloud SDK'

        - script: |
            pytest -v --docs-tests -m integration --bigquery tests/integration/test_script_runner.py
          displayName: 'pytest'
          env:
            # GCP credentials
            GOOGLE_APPLICATION_CREDENTIALS: $(gcp_authkey.secureFilePath)
            GE_TEST_GCP_PROJECT: $(GE_TEST_GCP_PROJECT)
            GE_TEST_BIGQUERY_DATASET: $(GE_TEST_BIGQUERY_DATASET)

    - job: test_docs_mssql
      timeoutInMinutes: 30
      condition: or(eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true), eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true), eq(variables.isDevelop, true), eq(variables.isManual, true))
      variables:
        python.version: '3.8'
      services:
        mssql: mssql

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'

        - script: |
            pip install --constraint constraints-dev.txt ".[test, mssql]" pytest-azurepipelines
          displayName: 'Install dependencies'

        - script: |
            sqlcmd -U sa -P "ReallyStrongPwd1234%^&*" -Q "CREATE DATABASE test_ci;" -o create_db_output.txt
          displayName: 'Create MSSQL database test_ci'

        - script: |
            # Note expect_column_values_to_only_contain_vowels is skipped because metrics are not implemented for MSSQL.
            pytest -v --docs-tests -m integration --mssql -k "not test_docs[expect_column_values_to_only_contain_vowels]" tests/integration/test_script_runner.py
          displayName: 'pytest'

    - job: test_docs_snowflake
      timeoutInMinutes: 30
      condition: and(or(eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true), eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true), eq(variables.isDevelop, true), eq(variables.isManual, true)), ne(variables['SYSTEM.PULLREQUEST.ISFORK'], true))
      variables:
        python.version: '3.8'

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'

        - script: |
            pip install --constraint constraints-dev.txt ".[test, snowflake]" pytest-azurepipelines
          displayName: 'Install dependencies'

        - script: |
            pytest -v --docs-tests -m integration --snowflake tests/integration/test_script_runner.py
          displayName: 'pytest'
          env:
            # snowflake credentials
            SNOWFLAKE_ACCOUNT: $(SNOWFLAKE_ACCOUNT)
            SNOWFLAKE_USER: $(SNOWFLAKE_USER)
            SNOWFLAKE_PW: $(SNOWFLAKE_PW)
            SNOWFLAKE_DATABASE: $(SNOWFLAKE_DATABASE)
            SNOWFLAKE_SCHEMA: $(SNOWFLAKE_SCHEMA)
            SNOWFLAKE_WAREHOUSE: $(SNOWFLAKE_WAREHOUSE)
            SNOWFLAKE_ROLE: $(SNOWFLAKE_ROLE)

    - job: test_docs_redshift
      timeoutInMinutes: 30
      condition: and(or(eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true), eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true), eq(variables.isDevelop, true), eq(variables.isManual, true)), ne(variables['SYSTEM.PULLREQUEST.ISFORK'], true))
      variables:
        python.version: '3.8'

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'

        - script: |
            # "Deprecated API features detected" warning/error for test_docs[split_data_on_whole_table_redshift] when pandas>=2.0
            pip install --constraint constraints-dev.txt ".[test, redshift]" pytest-azurepipelines "pandas<2.0.0"
          displayName: 'Install dependencies'
        - script: |
            pytest -v --docs-tests -m integration --redshift tests/integration/test_script_runner.py
          displayName: 'pytest'
          env:
            # redshift credentials
            REDSHIFT_USERNAME: $(REDSHIFT_USERNAME)
            REDSHIFT_PASSWORD: $(REDSHIFT_PASSWORD)
            REDSHIFT_HOST: $(REDSHIFT_HOST)
            REDSHIFT_PORT: $(REDSHIFT_PORT)
            REDSHIFT_DATABASE: $(REDSHIFT_DATABASE)
            REDSHIFT_SSLMODE: $(REDSHIFT_SSLMODE)
            # aws credentials
            AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
            AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
            AWS_DEFAULT_REGION: $(AWS_DEFAULT_REGION)

    - job: test_docs_aws
      timeoutInMinutes: 30
      condition: and(or(eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true), eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true), eq(variables.isDevelop, true), eq(variables.isManual, true)), ne(variables['SYSTEM.PULLREQUEST.ISFORK'], true))
      variables:
        python.version: '3.8'

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'

        - script: |
            pip install --constraint constraints-dev.txt ".[test]" pytest-azurepipelines git+https://github.com/awslabs/aws-glue-libs.git
          displayName: 'Install dependencies'

        - script: |
            pytest -v --docs-tests -m integration --aws tests/integration/test_script_runner.py
          displayName: 'pytest'
          env:
            AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
            AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
            AWS_DEFAULT_REGION: $(AWS_DEFAULT_REGION)

    - job: test_docs_aws_spark
      timeoutInMinutes: 30
      condition: and(or(eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true), eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true), eq(variables.isDevelop, true), eq(variables.isManual, true)), ne(variables['SYSTEM.PULLREQUEST.ISFORK'], true))
      variables:
        python.version: '3.8'
        spark.version: '3.3.2'
        matching_aws_java_sdk_bundle_version: '1.11.1026'

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'
        - script: |
            pip install pyspark==$(spark.version)
          displayName: Install Pyspark $(spark.version)
        - script: |
            export JAVA_HOME=$JAVA_HOME_11_X64
          displayName: Set JAVA_HOME  to existing directory
        - script: |
            wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/$(spark.version)/hadoop-aws-$(spark.version).jar
            wget https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/$(matching_aws_java_sdk_bundle_version)/aws-java-sdk-bundle-$(matching_aws_java_sdk_bundle_version).jar
            export pyspark_dir=`python -c 'import pyspark; print(pyspark.__path__[0] + "/jars/")'`
            mv hadoop-aws-$(spark.version).jar $pyspark_dir
            mv aws-java-sdk-bundle-$(matching_aws_java_sdk_bundle_version).jar $pyspark_dir

          displayName: download the AWS JARs and move to pyspark's JAR directory.
        - script: |
            pip install --constraint constraints-dev.txt ".[test, spark]" pytest-azurepipelines git+https://github.com/awslabs/aws-glue-libs.git
          displayName: 'Install dependencies'
        - script: |
            pytest -v --docs-tests -m integration --aws --spark tests/integration/test_script_runner.py
          displayName: 'pytest'
          env:
            AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
            AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
            AWS_DEFAULT_REGION: $(AWS_DEFAULT_REGION)

    - job: test_docs_azure
      timeoutInMinutes: 30
      condition: and(or(eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true), eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true), eq(variables.isDevelop, true), eq(variables.isManual, true)), ne(variables['SYSTEM.PULLREQUEST.ISFORK'], true))
      variables:
        python.version: '3.8'

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'

        - script: |
            pip install --constraint constraints-dev.txt ".[test, azure]" pytest-azurepipelines
          displayName: 'Install dependencies'

        - script: |
            pytest -v --docs-tests -m integration --azure tests/integration/test_script_runner.py
          displayName: 'pytest'
          env:
            AZURE_CREDENTIAL: $(AZURE_CREDENTIAL)
            AZURE_ACCESS_KEY: $(AZURE_ACCESS_KEY)

    - job: test_docs_trino
      timeoutInMinutes: 30
      condition: or(eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true), eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true), eq(variables.isDevelop, true), eq(variables.isManual, true))
      variables:
        python.version: '3.8'
      services:
        trino: trino

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'

        - script: |
            pip install --constraint constraints-dev.txt ".[test, trino]" pytest-azurepipelines
          displayName: 'Install dependencies'
        - script: |
            pytest -v --docs-tests -m integration --trino tests/integration/test_script_runner.py
          displayName: 'pytest'

    - job: test_docs_athena
      timeoutInMinutes: 30
      condition: or(eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true), eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true), eq(variables.isDevelop, true), eq(variables.isManual, true))
      variables:
        python.version: '3.8'

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'

        - script: |
            pip install --constraint constraints-dev.txt ".[test, athena]" pytest-azurepipelines
          displayName: 'Install dependencies'

        - script: |
            pytest -v --docs-tests -m integration --athena tests/integration/test_script_runner.py
          displayName: 'pytest'
          env:
            ATHENA_DB_NAME: $(ATHENA_DB_NAME)
            ATHENA_STAGING_S3: $(ATHENA_STAGING_S3)
            ATHENA_DATA_BUCKET: $(ATHENA_DATA_BUCKET)
            ATHENA_TEN_TRIPS_DB_NAME: $(ATHENA_TEN_TRIPS_DB_NAME)
            # aws credentials
            AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
            AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
            AWS_DEFAULT_REGION: $(AWS_DEFAULT_REGION)

    - job: test_docs_multiple_database
      timeoutInMinutes: 30
      condition: or(
          eq(stageDependencies.scope_check.changes.outputs['CheckDocsDependenciesChanges.DocsDependenciesChanged'], true),
          eq(stageDependencies.scope_check.changes.outputs['CheckDocsChanges.DocsChanged'], true),
          eq(variables.isDevelop, true),
          eq(variables.isManual, true)
        )
      variables:
        python.version: '3.8'
      services:
        mysql: mysql
        postgres: postgres

      steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(python.version)'
          displayName: 'Use Python $(python.version)'

        - script: |
            pip install --constraint constraints-dev.txt ".[test, mysql, postgresql]" pytest-azurepipelines
          displayName: 'Install dependencies'

        - script: |
            printf 'Waiting for MySQL database to accept connections'
            until mysql --host=localhost --protocol=TCP --port=3306 --user=root --password='' --execute "SHOW DATABASES"; do
              printf '.'
              sleep 1;
            done;
          displayName: Wait for database to initialise

        - script: |
            echo "SET GLOBAL sql_mode=(SELECT REPLACE(@@sql_mode,'ONLY_FULL_GROUP_BY',''));" > mysql_setup_script.sql
            mysql --host=localhost --protocol=TCP --port=3306 --user=root --password='' --reconnect < mysql_setup_script.sql
          displayName: 'Configure mysql'

        - script: |
            pytest -v --docs-tests -m integration --mysql --postgresql tests/integration/test_script_runner.py
          displayName: 'pytest'
